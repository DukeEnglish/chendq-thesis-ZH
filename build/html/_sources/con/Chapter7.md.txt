# Chapter 7 Conclusions

在这篇论文中，我们对神经阅读理解的基础（第一部分）和应用（第二部分）进行了全面的概述，以及自2015年末神经阅读理解出现以来，我们是如何为这一领域的发展做出贡献的。

在第二章中，我们回顾了阅读理解的历史，这可以追溯到20世纪70年代。当时，研究人员已经认识到它作为测试计算机程序语言理解能力的一种适当方法的重要性。然而，直到2010年代，阅读理解才开始被表述为一个监督学习问题，以三组（短文、问题、答案）的形式收集人类标记的训练例子。自2015年以来，通过对大规模监督数据集的创建，以及神经阅读理解模型的开发，该领域已经完成了重塑。尽管到目前为止只有3年的时间，但这个领域的发展速度惊人。在建立更好的数据集和更有效的模型方面的创新也相继出现，它们都对该领域的发展做出了贡献。我们还正式定义了阅读理解的任务，并描述了四种最常见的问题类型：完形填空、多项选择、跨度预测和自由形式的答案及其评价指标。

在第三章中，我们涵盖了现代神经阅读理解模型的所有要素。我们介绍了斯坦福专注读者，这是我们首先为CNN/每日邮报的完形填空任务提出的，是该领域最早的神经阅读压缩模型之一。我们的模型在其他完形填空和多项选择题中得到了广泛的研究。后来我们将其应用到球队数据集中，并取得了当时最先进的性能。与传统的基于特征的模型相比，该模型不依赖于任何下游语言特征，所有参数共同优化。通过实验和仔细的手工分析，我们得出结论，神经模型在识别词汇匹配和释义方面更强大。我们还讨论了最近在开发神经阅读理解模型方面的进展，包括更好的单词表示、注意机制、LSTMs的替代品，以及其他进展，如训练目标和数据增强。

在第四章中，我们讨论了该领域未来的工作和有待解决的问题。我们检查了小队的错误案例（对于我们的模型和超越人类表现的最先进的模型）。我们的结论是，这些模型对文本进行了非常细致的匹配，但它们仍然难以理解实体与文本中所表达的事件之间的内在结构。我们稍后讨论了模型和数据集的未来工作。对于模型，我们认为除了精确性之外，还有其他被忽略的重要方面，这些方面是我们在未来需要改进的，包括速度和可伸缩性、健壮性和可解释性。我们也相信未来的模型将需要更多的结构和模块来解决更困难的阅读理解问题。后的数据集，我们讨论了最近的数据集开发——这些数据集需要更复杂的推理在句子或文件，或需要处理长文档，或需要生成自由格式的答案，而不是提取——荷兰国际集团（ing）单跨，或者通过预测何时没有答案。最后，我们研究了几个我们认为对未来神经阅读理解很重要的问题。

在第二部分中，我们想要回答的关键问题是：阅读理解仅仅是衡量语言理解的一个任务吗？如果我们能够构建一个高性能的阅读理解系统，能够在短时间内回答理解问题，那么它是否能够实现有用的应用呢？

在第五章中，我们展示了我们可以结合信息检索技术和神经阅读理解模型来构建一个开放领域的问答系统：在大型百科全书或网络上回答一般问题。特别地，我们在DRQA项目中实现了这个想法，这是一个大型的、基于英语维基百科的真实问题回答系统。我们在多个问题回答基准上对系统进行了评估，证明了该方法的可行性。我们还提出了一个程序，从其他问答资源中自动创建额外的远程监督培训示例，并证明了该方法的有效性。我们希望我们的工作在这一研究方向上迈出第一步，这种信息检索和神经阅读理解相结合的新范式最终将导致新一代开放领域的问题回答系统。

在第6章中，我们讨论了会话问题的回答问题，即计算机系统需要理解文本段落并回答会话中出现的一系列问题。为了解决这个问题，我们构建了COQA：一个会话性问题回答挑战，用于测量机器参与问答式对话的能力。我们的数据集包含127k个带答案的问题，来自七个不同领域的8k个关于文本段落的对话。基于会话和阅读推理模型，我们还为这项新任务建立了几个具有竞争力的基线。我们相信，构建这样的系统将在我们未来的会话人工智能系统中发挥至关重要的作用。

总之，我们对过去三年在这一领域取得的进展感到非常兴奋，并很高兴能够为这一领域作出贡献。同时，我们也深信，要达到真正的人的阅读理解水平还有很长的路要走，我们仍然面临着巨大的挑战，还有很多悬而未决的问题需要我们在未来加以解决。一个关键的挑战是，我们仍然没有好的方法来达到更深层次的阅读理解——这些问题需要理解文本的推理和含义。通常这种情况会发生在“如何”或“为什么”的问题上，比如在故事中，“辛西娅为什么对她的母亲不高兴？”，约翰试图怎样弥补他最初的错误？在未来，我们必须解决所讨论内容的基础科学问题，而不仅仅是通过文本匹配来回答问题，以达到这种阅读理解的水平。

我们也希望鼓励更多的研究人员致力于应用，或将神经阅读理解应用于新的领域或任务。我们相信，它将引导我们构建更好的问答和会话代理，并希望看到这些想法在行业应用中得到实现和发展。